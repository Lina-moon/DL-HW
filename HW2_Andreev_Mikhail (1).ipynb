{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW2_Andreev_Mikhail.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jBlkzBr0z3f"
      },
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import cv2 \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUYOHQ8Rpnzt",
        "outputId": "4415a467-16db-4c60-e2d4-70d3bf561e1a"
      },
      "source": [
        "!unzip /content/lesson1_dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/lesson1_dataset.zip\n",
            "   creating: logloss_1/\n",
            "  inflating: logloss_1/m3.png        \n",
            "  inflating: logloss_1/logloss_1logloss_1_34.png  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/logloss_1/\n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_34.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_20.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_20.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_21.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_21.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_35.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_35.png  \n",
            "  inflating: logloss_1/m2.png        \n",
            "  inflating: logloss_1/logloss_1logloss_1_23.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_23.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_37.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_37.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_36.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_36.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_22.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_22.png  \n",
            "  inflating: logloss_1/m1.png        \n",
            "  inflating: logloss_1/logloss_1logloss_1_26.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_26.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_32.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_32.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_33.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_33.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_27.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_27.png  \n",
            "  inflating: logloss_1/m4.png        \n",
            "  inflating: __MACOSX/logloss_1/._m4.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_19.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_19.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_31.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_31.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_25.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_25.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_24.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_24.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_30.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_30.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_18.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_18.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_8.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_8.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_9.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_9.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_4.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_4.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_5.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_5.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_7.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_7.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_6.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_6.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_2.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_2.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_3.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_3.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_1.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_1.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_0.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_0.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_15.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_15.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_29.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_29.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_28.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_28.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_14.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_14.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_16.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_16.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_17.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_17.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_13.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_13.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_12.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_12.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_38.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_38.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_10.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_10.png  \n",
            "  inflating: logloss_1/logloss_1logloss_1_11.png  \n",
            "  inflating: __MACOSX/logloss_1/._logloss_1logloss_1_11.png  \n",
            "   creating: logloss_0/\n",
            "  inflating: logloss_0/logloss_0_14.png  \n",
            "   creating: __MACOSX/logloss_0/\n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_14.png  \n",
            "  inflating: logloss_0/logloss_0_15.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_15.png  \n",
            "  inflating: logloss_0/logloss_0_17.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_17.png  \n",
            "  inflating: logloss_0/logloss_0_16.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_16.png  \n",
            "  inflating: logloss_0/logloss_0_12.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_12.png  \n",
            "  inflating: logloss_0/logloss_0_9.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_9.png  \n",
            "  inflating: logloss_0/logloss_0_8.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_8.png  \n",
            "  inflating: logloss_0/logloss_0_13.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_13.png  \n",
            "  inflating: logloss_0/logloss_0_11.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_11.png  \n",
            "  inflating: logloss_0/logloss_0_10.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_10.png  \n",
            "  inflating: logloss_0/logloss_0_21.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_21.png  \n",
            "  inflating: logloss_0/logloss_0_6.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_6.png  \n",
            "  inflating: logloss_0/logloss_0_7.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_7.png  \n",
            "  inflating: logloss_0/logloss_0_20.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_20.png  \n",
            "  inflating: logloss_0/logloss_0_5.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_5.png  \n",
            "  inflating: logloss_0/logloss_0_4.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_4.png  \n",
            "  inflating: logloss_0/logloss_0_0.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_0.png  \n",
            "  inflating: logloss_0/logloss_0_1.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_1.png  \n",
            "  inflating: logloss_0/logloss_0_18.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_18.png  \n",
            "  inflating: logloss_0/logloss_0_3.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_3.png  \n",
            "  inflating: logloss_0/logloss_0_2.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_2.png  \n",
            "  inflating: logloss_0/logloss_0_19.png  \n",
            "  inflating: __MACOSX/logloss_0/._logloss_0_19.png  \n",
            "  inflating: __MACOSX/._logloss_0    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mumw-Ai04lmJ"
      },
      "source": [
        "def read_files(X, Y, path, ans):\n",
        "  files = os.listdir(path)\n",
        "  for name in files:\n",
        "    img = cv2.imread(path + '/' + name, 0)\n",
        "    if img.shape != 0:\n",
        "      img = cv2.resize(img, (256, 256))\n",
        "      vect = img.reshape(1, 256 ** 2)\n",
        "      vect = vect / 255.\n",
        "      X = vect if (X is None) else np.vstack((X, vect)) \n",
        "      Y = np.append(Y, ans)\n",
        "  return X, Y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNjB-n6b6KJZ"
      },
      "source": [
        "class MyClass(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.x = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(Y)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIU6T7GUOem4"
      },
      "source": [
        "X = None\n",
        "Y = np.array([])\n",
        "X, Y = read_files(X, Y, \"/content/logloss_0\", 0)\n",
        "X, Y = read_files(X, Y, \"/content/logloss_1\", 1)\n",
        "\n",
        "data = MyClass(X, Y)\n",
        "train_data, test_data = torch.utils.data.random_split(data, [int(0.8*len(data)), int(0.2*len(data))])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pReWRsiJrqy5",
        "outputId": "ef5e61ea-c363-4108-8c42-71f3120fd047"
      },
      "source": [
        "data.__len__()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqgxdsNdr4Mq",
        "outputId": "0116d139-2c0d-4b13-d402-528867a3665b"
      },
      "source": [
        "train_data.__len__()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dxm68Rfq-aM"
      },
      "source": [
        "loader_train = DataLoader(dataset=train_data, batch_size=5, shuffle=True)\r\n",
        "loader_test = DataLoader(dataset=test_data, shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydRceVVIS3eo"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(65536, 1024),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 2),\n",
        "    nn.Softmax()\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "og9j3Q3vAep-",
        "outputId": "cb99a9a2-515d-45e5-e7cd-f1455d80d461"
      },
      "source": [
        "pip install torch-summary"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-summary\n",
            "  Downloading https://files.pythonhosted.org/packages/ca/db/93d18c84f73b214acfa4d18051d6f4263eee3e044c408928e8abe941a22c/torch_summary-1.4.5-py3-none-any.whl\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchsummary"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4YindMDp56qx",
        "outputId": "14d57472-d183-4ca4-bafc-a87c8e8b7162"
      },
      "source": [
        "\r\n",
        "from torchsummary import summary\r\n",
        "summary(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b25799145bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: summary() missing 1 required positional argument: 'input_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipk7dkUwaBp8"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JQQhGTSaEdv",
        "outputId": "a0f28ce2-d0c3-40f3-fff9-e91a524b6b17"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=65536, out_features=1024, bias=True)\n",
              "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): Dropout(p=0.2, inplace=False)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (6): Dropout(p=0.2, inplace=False)\n",
              "  (7): ReLU()\n",
              "  (8): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (10): Dropout(p=0.2, inplace=False)\n",
              "  (11): ReLU()\n",
              "  (12): Linear(in_features=1024, out_features=2, bias=True)\n",
              "  (13): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyjZjSvnsll8",
        "outputId": "1b4d0d49-55ad-4fc2-8c76-3d06e0668a5c"
      },
      "source": [
        "epochs = 20\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    for j, (x, y) in enumerate(loader_train):\n",
        "        optimizer.zero_grad()\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        y_pred = model(x.float())\n",
        "        loss = criterion(y_pred, y.long())\n",
        "        print(f\"Epoch {i}\\t iter {j}\\t loss {loss}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\t iter 0\t loss 0.7851999998092651\n",
            "Epoch 0\t iter 1\t loss 0.7686403393745422\n",
            "Epoch 0\t iter 2\t loss 0.6015312075614929\n",
            "Epoch 0\t iter 3\t loss 0.6214414834976196\n",
            "Epoch 0\t iter 4\t loss 0.42758139967918396\n",
            "Epoch 0\t iter 5\t loss 0.38301652669906616\n",
            "Epoch 0\t iter 6\t loss 0.7105097770690918\n",
            "Epoch 0\t iter 7\t loss 0.867392361164093\n",
            "Epoch 0\t iter 8\t loss 0.6012037992477417\n",
            "Epoch 0\t iter 9\t loss 0.8334954380989075\n",
            "Epoch 0\t iter 10\t loss 0.8089786767959595\n",
            "Epoch 1\t iter 0\t loss 0.31854376196861267\n",
            "Epoch 1\t iter 1\t loss 0.6660093069076538\n",
            "Epoch 1\t iter 2\t loss 0.3622705936431885\n",
            "Epoch 1\t iter 3\t loss 0.7964896559715271\n",
            "Epoch 1\t iter 4\t loss 0.7020136117935181\n",
            "Epoch 1\t iter 5\t loss 0.4978969991207123\n",
            "Epoch 1\t iter 6\t loss 0.44476231932640076\n",
            "Epoch 1\t iter 7\t loss 0.5152632594108582\n",
            "Epoch 1\t iter 8\t loss 0.5052732229232788\n",
            "Epoch 1\t iter 9\t loss 0.3243638873100281\n",
            "Epoch 1\t iter 10\t loss 1.2230174541473389\n",
            "Epoch 2\t iter 0\t loss 0.33779382705688477\n",
            "Epoch 2\t iter 1\t loss 0.7509219646453857\n",
            "Epoch 2\t iter 2\t loss 0.6090085506439209\n",
            "Epoch 2\t iter 3\t loss 0.4582284092903137\n",
            "Epoch 2\t iter 4\t loss 0.5157906413078308\n",
            "Epoch 2\t iter 5\t loss 0.4373810887336731\n",
            "Epoch 2\t iter 6\t loss 0.43598777055740356\n",
            "Epoch 2\t iter 7\t loss 0.7866203188896179\n",
            "Epoch 2\t iter 8\t loss 0.7477506995201111\n",
            "Epoch 2\t iter 9\t loss 0.32326507568359375\n",
            "Epoch 2\t iter 10\t loss 0.3427950143814087\n",
            "Epoch 3\t iter 0\t loss 0.3254353106021881\n",
            "Epoch 3\t iter 1\t loss 0.4347004294395447\n",
            "Epoch 3\t iter 2\t loss 0.5932130813598633\n",
            "Epoch 3\t iter 3\t loss 0.33900052309036255\n",
            "Epoch 3\t iter 4\t loss 0.4988139569759369\n",
            "Epoch 3\t iter 5\t loss 0.6335563063621521\n",
            "Epoch 3\t iter 6\t loss 0.5604698061943054\n",
            "Epoch 3\t iter 7\t loss 0.6239967942237854\n",
            "Epoch 3\t iter 8\t loss 0.49485769867897034\n",
            "Epoch 3\t iter 9\t loss 0.3911972939968109\n",
            "Epoch 3\t iter 10\t loss 0.7711365818977356\n",
            "Epoch 4\t iter 0\t loss 0.5234265327453613\n",
            "Epoch 4\t iter 1\t loss 0.33008891344070435\n",
            "Epoch 4\t iter 2\t loss 0.36549443006515503\n",
            "Epoch 4\t iter 3\t loss 0.3807271122932434\n",
            "Epoch 4\t iter 4\t loss 0.6150978803634644\n",
            "Epoch 4\t iter 5\t loss 0.5230967998504639\n",
            "Epoch 4\t iter 6\t loss 0.523315966129303\n",
            "Epoch 4\t iter 7\t loss 0.727389931678772\n",
            "Epoch 4\t iter 8\t loss 0.5545212030410767\n",
            "Epoch 4\t iter 9\t loss 0.3798750042915344\n",
            "Epoch 4\t iter 10\t loss 0.7947289943695068\n",
            "Epoch 5\t iter 0\t loss 0.31376659870147705\n",
            "Epoch 5\t iter 1\t loss 0.7632726430892944\n",
            "Epoch 5\t iter 2\t loss 0.36984047293663025\n",
            "Epoch 5\t iter 3\t loss 0.31488266587257385\n",
            "Epoch 5\t iter 4\t loss 0.5145082473754883\n",
            "Epoch 5\t iter 5\t loss 0.322937548160553\n",
            "Epoch 5\t iter 6\t loss 0.7140825390815735\n",
            "Epoch 5\t iter 7\t loss 0.5186864733695984\n",
            "Epoch 5\t iter 8\t loss 0.49517741799354553\n",
            "Epoch 5\t iter 9\t loss 0.7048691511154175\n",
            "Epoch 5\t iter 10\t loss 0.8011055588722229\n",
            "Epoch 6\t iter 0\t loss 0.34091976284980774\n",
            "Epoch 6\t iter 1\t loss 0.6820653676986694\n",
            "Epoch 6\t iter 2\t loss 0.5152557492256165\n",
            "Epoch 6\t iter 3\t loss 0.32057785987854004\n",
            "Epoch 6\t iter 4\t loss 0.6537255048751831\n",
            "Epoch 6\t iter 5\t loss 0.5954157114028931\n",
            "Epoch 6\t iter 6\t loss 0.5121656656265259\n",
            "Epoch 6\t iter 7\t loss 0.6643849015235901\n",
            "Epoch 6\t iter 8\t loss 0.7179266214370728\n",
            "Epoch 6\t iter 9\t loss 0.746519923210144\n",
            "Epoch 6\t iter 10\t loss 0.45889589190483093\n",
            "Epoch 7\t iter 0\t loss 0.3161923885345459\n",
            "Epoch 7\t iter 1\t loss 0.4476017355918884\n",
            "Epoch 7\t iter 2\t loss 0.3199564814567566\n",
            "Epoch 7\t iter 3\t loss 0.4988633990287781\n",
            "Epoch 7\t iter 4\t loss 0.31407588720321655\n",
            "Epoch 7\t iter 5\t loss 0.5032393932342529\n",
            "Epoch 7\t iter 6\t loss 0.3400319516658783\n",
            "Epoch 7\t iter 7\t loss 0.9143410921096802\n",
            "Epoch 7\t iter 8\t loss 0.3156227469444275\n",
            "Epoch 7\t iter 9\t loss 0.3375212550163269\n",
            "Epoch 7\t iter 10\t loss 0.8443250060081482\n",
            "Epoch 8\t iter 0\t loss 0.31978440284729004\n",
            "Epoch 8\t iter 1\t loss 0.5224462151527405\n",
            "Epoch 8\t iter 2\t loss 0.42126840353012085\n",
            "Epoch 8\t iter 3\t loss 0.4918197691440582\n",
            "Epoch 8\t iter 4\t loss 0.5456479787826538\n",
            "Epoch 8\t iter 5\t loss 0.3146868050098419\n",
            "Epoch 8\t iter 6\t loss 0.514143705368042\n",
            "Epoch 8\t iter 7\t loss 0.37509027123451233\n",
            "Epoch 8\t iter 8\t loss 0.32668212056159973\n",
            "Epoch 8\t iter 9\t loss 0.47975602746009827\n",
            "Epoch 8\t iter 10\t loss 0.36122334003448486\n",
            "Epoch 9\t iter 0\t loss 0.41021257638931274\n",
            "Epoch 9\t iter 1\t loss 0.3463076949119568\n",
            "Epoch 9\t iter 2\t loss 0.9723483920097351\n",
            "Epoch 9\t iter 3\t loss 0.5746331214904785\n",
            "Epoch 9\t iter 4\t loss 0.580469012260437\n",
            "Epoch 9\t iter 5\t loss 0.3259424567222595\n",
            "Epoch 9\t iter 6\t loss 0.5697674751281738\n",
            "Epoch 9\t iter 7\t loss 0.5197194218635559\n",
            "Epoch 9\t iter 8\t loss 0.516273558139801\n",
            "Epoch 9\t iter 9\t loss 0.31731635332107544\n",
            "Epoch 9\t iter 10\t loss 1.3096725940704346\n",
            "Epoch 10\t iter 0\t loss 0.3536432385444641\n",
            "Epoch 10\t iter 1\t loss 0.3687564432621002\n",
            "Epoch 10\t iter 2\t loss 0.546920120716095\n",
            "Epoch 10\t iter 3\t loss 0.7036987543106079\n",
            "Epoch 10\t iter 4\t loss 0.5052682757377625\n",
            "Epoch 10\t iter 5\t loss 0.7592825889587402\n",
            "Epoch 10\t iter 6\t loss 0.32955390214920044\n",
            "Epoch 10\t iter 7\t loss 0.7041365504264832\n",
            "Epoch 10\t iter 8\t loss 0.6174412965774536\n",
            "Epoch 10\t iter 9\t loss 0.44640031456947327\n",
            "Epoch 10\t iter 10\t loss 0.36883753538131714\n",
            "Epoch 11\t iter 0\t loss 0.3135101795196533\n",
            "Epoch 11\t iter 1\t loss 0.5057672262191772\n",
            "Epoch 11\t iter 2\t loss 0.3193594813346863\n",
            "Epoch 11\t iter 3\t loss 0.7292672991752625\n",
            "Epoch 11\t iter 4\t loss 0.3585263192653656\n",
            "Epoch 11\t iter 5\t loss 0.32073259353637695\n",
            "Epoch 11\t iter 6\t loss 0.31923437118530273\n",
            "Epoch 11\t iter 7\t loss 0.37370508909225464\n",
            "Epoch 11\t iter 8\t loss 0.47677287459373474\n",
            "Epoch 11\t iter 9\t loss 0.696826696395874\n",
            "Epoch 11\t iter 10\t loss 0.34251660108566284\n",
            "Epoch 12\t iter 0\t loss 0.4029305577278137\n",
            "Epoch 12\t iter 1\t loss 0.3170259892940521\n",
            "Epoch 12\t iter 2\t loss 0.5300149321556091\n",
            "Epoch 12\t iter 3\t loss 0.4925804138183594\n",
            "Epoch 12\t iter 4\t loss 0.3180408477783203\n",
            "Epoch 12\t iter 5\t loss 0.6606553196907043\n",
            "Epoch 12\t iter 6\t loss 0.3153408169746399\n",
            "Epoch 12\t iter 7\t loss 0.5138163566589355\n",
            "Epoch 12\t iter 8\t loss 0.3143230378627777\n",
            "Epoch 12\t iter 9\t loss 0.4512913227081299\n",
            "Epoch 12\t iter 10\t loss 0.31485575437545776\n",
            "Epoch 13\t iter 0\t loss 0.6866812705993652\n",
            "Epoch 13\t iter 1\t loss 0.3188154399394989\n",
            "Epoch 13\t iter 2\t loss 0.3850093185901642\n",
            "Epoch 13\t iter 3\t loss 0.4093259871006012\n",
            "Epoch 13\t iter 4\t loss 0.3138042390346527\n",
            "Epoch 13\t iter 5\t loss 0.3141658902168274\n",
            "Epoch 13\t iter 6\t loss 0.3600916266441345\n",
            "Epoch 13\t iter 7\t loss 0.38952094316482544\n",
            "Epoch 13\t iter 8\t loss 0.327078253030777\n",
            "Epoch 13\t iter 9\t loss 0.7088303565979004\n",
            "Epoch 13\t iter 10\t loss 0.318888396024704\n",
            "Epoch 14\t iter 0\t loss 0.34393709897994995\n",
            "Epoch 14\t iter 1\t loss 0.3160514831542969\n",
            "Epoch 14\t iter 2\t loss 0.7005033493041992\n",
            "Epoch 14\t iter 3\t loss 0.5108962059020996\n",
            "Epoch 14\t iter 4\t loss 0.3185923993587494\n",
            "Epoch 14\t iter 5\t loss 0.3142716884613037\n",
            "Epoch 14\t iter 6\t loss 0.3500373661518097\n",
            "Epoch 14\t iter 7\t loss 0.38954514265060425\n",
            "Epoch 14\t iter 8\t loss 0.3144795894622803\n",
            "Epoch 14\t iter 9\t loss 0.5002061128616333\n",
            "Epoch 14\t iter 10\t loss 0.33737313747406006\n",
            "Epoch 15\t iter 0\t loss 0.9407464265823364\n",
            "Epoch 15\t iter 1\t loss 0.572957456111908\n",
            "Epoch 15\t iter 2\t loss 0.5122967958450317\n",
            "Epoch 15\t iter 3\t loss 0.3145870268344879\n",
            "Epoch 15\t iter 4\t loss 0.3136102259159088\n",
            "Epoch 15\t iter 5\t loss 0.32175177335739136\n",
            "Epoch 15\t iter 6\t loss 0.5327342748641968\n",
            "Epoch 15\t iter 7\t loss 0.36657771468162537\n",
            "Epoch 15\t iter 8\t loss 0.41066256165504456\n",
            "Epoch 15\t iter 9\t loss 0.513388991355896\n",
            "Epoch 15\t iter 10\t loss 0.737861156463623\n",
            "Epoch 16\t iter 0\t loss 0.5124422311782837\n",
            "Epoch 16\t iter 1\t loss 0.5370100140571594\n",
            "Epoch 16\t iter 2\t loss 0.6753820776939392\n",
            "Epoch 16\t iter 3\t loss 0.31914928555488586\n",
            "Epoch 16\t iter 4\t loss 0.6574112772941589\n",
            "Epoch 16\t iter 5\t loss 0.42958006262779236\n",
            "Epoch 16\t iter 6\t loss 0.419360488653183\n",
            "Epoch 16\t iter 7\t loss 0.3144995868206024\n",
            "Epoch 16\t iter 8\t loss 1.0645109415054321\n",
            "Epoch 16\t iter 9\t loss 0.3283511996269226\n",
            "Epoch 16\t iter 10\t loss 0.5192166566848755\n",
            "Epoch 17\t iter 0\t loss 0.38041380047798157\n",
            "Epoch 17\t iter 1\t loss 0.5133742094039917\n",
            "Epoch 17\t iter 2\t loss 0.45652565360069275\n",
            "Epoch 17\t iter 3\t loss 0.5143145322799683\n",
            "Epoch 17\t iter 4\t loss 0.6653598546981812\n",
            "Epoch 17\t iter 5\t loss 0.31354671716690063\n",
            "Epoch 17\t iter 6\t loss 0.38581687211990356\n",
            "Epoch 17\t iter 7\t loss 0.5062958002090454\n",
            "Epoch 17\t iter 8\t loss 0.3199405074119568\n",
            "Epoch 17\t iter 9\t loss 0.31492581963539124\n",
            "Epoch 17\t iter 10\t loss 0.3141546845436096\n",
            "Epoch 18\t iter 0\t loss 0.333636999130249\n",
            "Epoch 18\t iter 1\t loss 0.5054022073745728\n",
            "Epoch 18\t iter 2\t loss 0.4751652777194977\n",
            "Epoch 18\t iter 3\t loss 0.327179491519928\n",
            "Epoch 18\t iter 4\t loss 0.32414183020591736\n",
            "Epoch 18\t iter 5\t loss 0.3920326232910156\n",
            "Epoch 18\t iter 6\t loss 0.33222198486328125\n",
            "Epoch 18\t iter 7\t loss 0.313987672328949\n",
            "Epoch 18\t iter 8\t loss 0.5478761792182922\n",
            "Epoch 18\t iter 9\t loss 0.3217194676399231\n",
            "Epoch 18\t iter 10\t loss 0.7997941970825195\n",
            "Epoch 19\t iter 0\t loss 0.4765685200691223\n",
            "Epoch 19\t iter 1\t loss 0.7106174826622009\n",
            "Epoch 19\t iter 2\t loss 0.314247190952301\n",
            "Epoch 19\t iter 3\t loss 0.45452824234962463\n",
            "Epoch 19\t iter 4\t loss 0.48721346259117126\n",
            "Epoch 19\t iter 5\t loss 0.3186565041542053\n",
            "Epoch 19\t iter 6\t loss 0.4700503945350647\n",
            "Epoch 19\t iter 7\t loss 0.40399137139320374\n",
            "Epoch 19\t iter 8\t loss 0.32033830881118774\n",
            "Epoch 19\t iter 9\t loss 0.4731106758117676\n",
            "Epoch 19\t iter 10\t loss 0.34423333406448364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tytOvmVy2iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd1308c-d313-424d-a440-c9623bdb116e"
      },
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "true = []\n",
        "\n",
        "for (x,y) in loader_test:\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    preds.append(int(torch.max(model(x.float()).data, 1)[1]))\n",
        "    true.append(int(y))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVhabBTODbnU",
        "outputId": "db3a085d-a1ac-4cde-cf82-1fa1af5d1465"
      },
      "source": [
        "print(true)\n",
        "print(preds)\n",
        "\n",
        "accuracy_score(true, preds)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9230769230769231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgvjW_I31o0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b746ee18-429d-45da-d0f5-62e2a33503c0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan 16 16:01:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    61W / 149W |  11366MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soeMbPt24In1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}